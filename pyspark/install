# This script assumes that the Jupyter pluggable notebook install script has already been executed

# Install Spark 2.2.1
rm -rf /opt/spark-*
wget -q https://archive.apache.org/dist/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz 
tar xvzf spark-2.2.1-bin-hadoop2.7.tgz
mv spark-2.2.1-bin-hadoop2.7 /opt
rm spark-2.2.1-bin-hadoop2.7.tgz
chown -R ubuntu:ubuntu /opt/spark-2.2.1-bin-hadoop2.7

# Install Hadoop 2.7.3
wget -q https://archive.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
tar -xzf hadoop-2.7.3.tar.gz
mv hadoop-2.7.3 /usr/local/hadoop

# Set environment variables
echo 'export SPARK_HOME=/opt/spark-2.2.1-bin-hadoop2.7' >> /home/ubuntu/.domino-defaults
echo 'export PYTHONPATH=${PYTHONPATH:-}:${SPARK_HOME:-}/python/' >> /home/ubuntu/.domino-defaults
echo 'export PYTHONPATH=${PYTHONPATH:-}:${SPARK_HOME:-}/python/lib/py4j-0.10.4-src.zip' >> /home/ubuntu/.domino-defaults
echo 'export PATH=${PATH:-}:${SPARK_HOME:-}/bin' >> /home/ubuntu/.domino-defaults
echo "export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop" >> /home/ubuntu/.domino-defaults
echo "export HADOOP_HOME=/usr/local/hadoop" >> /home/ubuntu/.domino-defaults
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-oracle/' >> /home/ubuntu/.domino-defaults
echo 'export PATH=${PATH:-}:${HADOOP_HOME:-}/bin' >> /home/ubuntu/.domino-defaults


# Make directories needed for the start script
mkdir -p /usr/local/hadoop/etc/hadoop
chmod +x /var/opt/workspaces/pyspark/start

